{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3, Week 2 In Class Exercise\n",
    "\n",
    "Least-squares linear regression\n",
    "\n",
    "**Before class reading: Mathematics in Geology Sections 6.1.1 - 6.2.7 & 7.3.3, Linear Algebra and Its Applications Section 6.5  **\n",
    "\n",
    "**Last week we:**\n",
    "- Learn how to deal with bivariate data (fitting lines, curves).\n",
    "- Apply line fitting to determine the spreading rate of various ocean ridges\n",
    "\n",
    "**Our goals for today:**\n",
    "- Least-squares problems in matrix form\n",
    "- Computational efficency of solving linearized equations with loops, vectors, and built-ing functions\n",
    "- Least-squares fitting of the Gutenberg-Richter law Bay Area catalog\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Run this cell as it is to setup your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Little Background on Fitting Geophysical Models to Data\n",
    "\n",
    "**What is a model?**\n",
    "\n",
    "**What is inversion/regression in Earth Science?**\n",
    "- statistical sampling (Bayesian Inferance, Monte Carlo, Genetic Algorithm, Particle Swarm (flocking), etc.\n",
    "- linearized inversion (start with a solution and interatively update the solution solving for derivatives of model parameters)\n",
    "- linear inversion\n",
    "\n",
    "**Examples of inversion/regression**\n",
    "\n",
    "<center> <h4>Linear Regression</h4> </center>\n",
    "\n",
    "<img src=\"./example_linear_regression.png\"><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h4>Fitting a Non-Linear Function and Data</h4> </center>\n",
    "\n",
    "<img src=\"./example_gmpe_fit.png\"><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h4>A Case Where the Model is Comprised of Synthetic Seismograms</h4> </center>\n",
    "\n",
    "<img src=\"./example_moment_tensor_long_valley.png\"><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <h4>Fitting a Variety of Geophysical Data for the Earthquake Source</h4> </center>\n",
    "\n",
    "<img src=\"./example_finite_source.png\"><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all of these examples the same basic method is used to fit the models to the data, although the time of data and the complexity of the models varies.\n",
    "\n",
    "**Least Squares as a method to perform inversion/regression i.e. fit a model to data**\n",
    "\n",
    "#### a+b*z=y(z)\n",
    "\n",
    "a + b*1.2= 3.2\n",
    "\n",
    "a + b*3.0= 5.0\n",
    "\n",
    "a - b*2.0=-1.0\n",
    "\n",
    "etc.\n",
    "\n",
    "#### Am=D\n",
    "\n",
    "How do we solve this system of linear equations? \n",
    "\n",
    "$\\mathbf {m=(A^T A)^{-1} A^T D}$\n",
    "\n",
    "What do the \"T\"s and \"-1\"s mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First some basic operations in Matrix Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix is a rectangular array of elements.\n",
    "\n",
    "$A=\\begin{bmatrix}\n",
    "a_{1} &  a_{2}\\\\ \n",
    "a_{3} &  a_{4}\n",
    "\\end{bmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 7],\n",
       "       [7, 3]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M=np.random.randint(1,9,4).reshape(2,2) #arguments low, high, number - returns an array - reshape makes matrix\n",
    "M\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 2],\n",
       "       [6, 7]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A=np.random.randint(1,9,4).reshape(2,2)\n",
    "A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  9],\n",
       "       [13, 10]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# addition\n",
    "M+A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3,  5],\n",
       "       [ 1, -4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtraction\n",
    "M-A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 14],\n",
       "       [42, 21]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elementwise multiplication\n",
    "M*A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _transpose_ of a matrix is found by swapping the rows and columns. The diagonal elements remain the same (for a square matrix).\n",
    "\n",
    "$A^{T}=\\begin{bmatrix}\n",
    "a_{1} &  a_{3}\\\\ \n",
    "a_{2} &  a_{4}\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_transpose(M):\n",
    "    m,n = np.shape(M) # m is number of rows, n is number of columns\n",
    "    M_transpose = np.zeros((n,m))\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            M_transpose[j][i] = ...\n",
    "            \n",
    "    return M_transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'ellipsis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fd148c54e682>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmatrix_transpose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-fc1dfbcdf838>\u001b[0m in \u001b[0;36mmatrix_transpose\u001b[0;34m(M)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mM_transpose\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mM_transpose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'ellipsis'"
     ]
    }
   ],
   "source": [
    "matrix_transpose(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30, 12],\n",
       "       [36, 42]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# multiplcation by a scalar\n",
    "A*6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiplication is a bit more complicated $AB=C$ = $C_{i,j}=\\Sigma_{k=1}^{n} A_{i,k}B_{k,j}$. Note that the product will have the same number of rows as $A$ and columns as $B$, and that $A$ needs to have as many columns and $B$ has rows.\n",
    "\n",
    "$A=\\begin{bmatrix}\n",
    "a_{1} &  a_{2}\\\\ \n",
    "a_{3} &  a_{4}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$B=\\begin{bmatrix}\n",
    "b_{1} &  b_{2}\\\\ \n",
    "b_{3} &  b_{4}\n",
    "\\end{bmatrix}$\n",
    "\n",
    "$C=\\begin{bmatrix}\n",
    "(a_{1} \\times b_{1}+a_{2} \\times b_{3}) &  (a_{1} \\times b_{2}+a_{2} \\times b_{4})\\\\ \n",
    "(a_{3} \\times b_{1}+a_{4} \\times b_{3}) &  (a_{3} \\times b_{2}+a_{4} \\times b_{4})\n",
    "\\end{bmatrix}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following table relates the matrix notation above to a coding notation. Lets finish writing the code for the matrix multiply below. Note that there is a triple nested for loop. The index i increments the slowest, j increments faster, and k increments the fast (for each j).\n",
    "\n",
    "<img src=\"./matrix_multiply_recursion_table.png\"><br/><br/><br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_mult(A,B):\n",
    "    m1,n1 = np.shape(A) # m is number of rows, n is number of columns\n",
    "    m2,n2 = np.shape(B) # m is number of rows, n is number of columns\n",
    "    C = np.zeros((m1,n2))\n",
    "    if n1 == m2:\n",
    "        for i in range(0,m1):\n",
    "            for j in range(0,n2):\n",
    "                for k in range(0,n1):\n",
    "                    C[i][j] = ...\n",
    "            \n",
    "        return C\n",
    "\n",
    "    else:\n",
    "        print('Number of columns in matrix 1 does not match number of rows in matrix 2')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_mult(A,M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A matrix raised to a power ($M^{2}$) follows the rules of matrix multiplication $M^{2}=\\Sigma_{k=1}^{n} M_{i,k}M_{k,j}$. This only works for square matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The _determinate_ of a 2x2 matrix is equal to $|A| = \\begin{vmatrix}\n",
    "a_{1} &  a_{2}\\\\ \n",
    "a_{3} &  a_{4}\n",
    "\\end{vmatrix} = a_{1}a_{4} - a_{2}a_{3}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_det(M):\n",
    "    m,n = np.shape(M) # m is number of rows, n is number of columns\n",
    "    if m == 2 & n == 2:\n",
    "        det = ...\n",
    "        return det\n",
    "    else:\n",
    "        print('Not a 2x2 matrix')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_det(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Division in matrix algbra is $A/M = M^{-1}A$ where $M^{-1}$ is the _inverse_ of M. $MM^{-1} = I$ where $I=\\begin{bmatrix}\n",
    "1 &  0\\\\ \n",
    "0 &  1\n",
    "\\end{bmatrix}$ is the _identity_ matrix, $AI = A$. For a 2x2 matrix the inverse is:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"inverse_2x2.png\" width=200>\n",
    ">Source: Mathematics in Geology, J. Ferguson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all matrices are invertable, for example if $|A|=0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_inv(M):\n",
    "    m,n = np.shape(M) # m is number of rows, n is number of columns\n",
    "    inv = np.zeros((m,n))\n",
    "    if m == 2 & n == 2:\n",
    "        inv[0][0] = .../matrix_det(M)\n",
    "        inv[0][1] = .../matrix_det(M)\n",
    "        inv[1][0] = .../matrix_det(M)\n",
    "        inv[1][1] = .../matrix_det(M)\n",
    "        return inv\n",
    "    else:\n",
    "        print('Not a 2x2 matrix')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_inv(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series of linear equations $a + b*{x_1} = d_{1}$, $a + b*{x_2} = d_{2}$, ... $a + b*{x_n} = d_{n}$ where $n$ is the number of data can be described with the series of matrices: $\\begin{bmatrix}\n",
    "1 &  x_{1}\\\\ \n",
    "1 &  x_{2}\\\\ \n",
    ". & . \\\\\n",
    ". & . \\\\\n",
    ". & . \\\\\n",
    "1 &  x_{n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "a \\\\\n",
    "b\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "d_{1} \\\\ d_{2} \\\\ . \\\\ . \\\\ . \\\\ d_{n} \\\\\n",
    "\\end{bmatrix}$ = $Am = D$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least-squares approximation can be formulated as:\n",
    "\n",
    "$m = (A{^T}A)^{-1}A{^T}D$.\n",
    "\n",
    "The least-squares approximation minimizes the squared difference between the observations and the model where the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets formulate the least squares inversion for the line fitting example from last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make up some randomly scattered linearly related data\n",
    "x = np.random.randn(100)*5\n",
    "m = 2\n",
    "b = np.random.rand(100)*10\n",
    "y = m*x+b\n",
    "\n",
    "\n",
    "m, b = np.polyfit(x,y,1)\n",
    "modelY=np.polyval([m, b],x)\n",
    "\n",
    "print ('slope: %7.3f, intercept: %4.1f'%\\\n",
    "    (m, b))\n",
    "\n",
    "# now plot the data and the best-fit line \n",
    "plt.figure(1,(5,5)) \n",
    "plt.plot(x,y,'o')\n",
    "plt.plot(x,modelY,'k-') \n",
    "plt.xlabel('X', fontsize=16);\n",
    "plt.ylabel('Y', fontsize=16);\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now write out the least squares matrix equation and invert for a and b of the line\n",
    "\n",
    "D=y.reshape(len(y),1)\n",
    "tmp=np.ones(len(x))\n",
    "\n",
    "A=np.column_stack((tmp,x))\n",
    "#A[1:5,:]\n",
    "\n",
    "invATA=matrix_inv(matrix_mult(matrix_transpose(A),A))\n",
    "ATD=matrix_mult(matrix_transpose(A),D)\n",
    "m=matrix_mult(invATA,ATD)\n",
    "\n",
    "print ('slope: %7.3f, intercept: %4.1f'%\\\n",
    "    (m[1], m[0]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gutenberg Richter Earthquake Occurrence Statistics\n",
    "\n",
    "\n",
    "Gutenberg and Richter found that when the logarithm of the number of earthquakes is plotted vs. magnitude that the distribution is linear, and a suitable model is log(N)=A+Bm, where N is the number of earthquakes, m is the magnitude and A and B are the slope and intercept of a line. For the example described above the B-value is equal to -1 (there are 10 times fewer earthquakes for an increase of one magnitude unit). An important point to keep in mind that these parameters are based on a primary earthquake catalog in which aftershocks have been removed. The process of aftershock removal is called declustering.\n",
    "\n",
    "Why is this important? The A- and B-values are often used to characterize the rates of earthquakes to identify regional variability. The B-value (slope parameter) is often used to distinquish between 'normal' and 'swarm-like' earthquake behavior. In geothermal areas it has been observed that the earthquake distribution is richer in small earthquakes indicating a B-value significantly less than -1. \n",
    "\n",
    "Gutenberg Richter is also used to characterize seismic hazard in a region by defining the annual rate of earthquake occurrence. In this module you will analyze a earthquake catalog downloaded from the Northern California Earthquake Data Center for a 100 km radius around the Berkeley Campus. You will estimate the Gutenberg Richter A- and B- values, and estimate the annual recurrence rates of large earthquake in the region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and decluster earthquake catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "# This catalog is a M0+ search centered at Berkeley radius=100km. \n",
    "# A big enough radius to include Loma Prieta but exclude Geysers.\n",
    "all_events_data=pd.read_csv('anss_catalog_1900to2018all.txt', sep=' ', delimiter=None, header=None,\n",
    "                 names = ['Year','Month','Day','Hour','Min','Sec','Lat','Lon','Mag'])\n",
    "\n",
    "#  create data arrays\n",
    "AE_year=all_events_data.Year.values\n",
    "AE_month=all_events_data.Month.values\n",
    "AE_day=all_events_data.Day.values\n",
    "AE_hour=all_events_data.Hour.values\n",
    "AE_mn=all_events_data.Min.values\n",
    "AE_sec=all_events_data.Sec.values\n",
    "AE_lat=all_events_data.Lat.values\n",
    "AE_lon=all_events_data.Lon.values\n",
    "AE_mag=all_events_data.Mag.values\n",
    "n_tot=len(AE_year)        #number of events \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the number of days from the first event\n",
    "AE_days=np.zeros(n_tot) # initialize the size of the array days\n",
    "for i in range(0,n_tot,1):\n",
    "    d0 = datetime.date(AE_year[0], AE_month[0], AE_day[0])\n",
    "    d1 = datetime.date(AE_year[i], AE_month[i], AE_day[i])\n",
    "    delta = d1 - d0\n",
    "    AE_days[i]=delta.days # fill days in with the number of days since the first event (7/1/1911)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function computes the spherical earth distance between to geographic points and is used in the\n",
    "#declustering algorithm below\n",
    "def haversine_np(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points\n",
    "    on the earth (specified in decimal degrees)\n",
    "\n",
    "    All args must be of equal length.\n",
    "    \n",
    "    The first pair can be singular and the second an array\n",
    "\n",
    "    \"\"\"\n",
    "    lon1, lat1, lon2, lat2 = map(np.radians, [lon1, lat1, lon2, lat2]) # convert degrees lat, lon to radians\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2  # great circle inside sqrt\n",
    "\n",
    "    c = 2 * np.arcsin(np.sqrt(a))   # great circle angular separation\n",
    "    km = 6371.0 * c   # great circle distance in km, earth radius = 6371.0 km\n",
    "    return km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decluster the Catalog  Note: This cell may take a few minute to complete\n",
    "cnt=0 # initialize a counting variable\n",
    "save=np.zeros((1,10000000),dtype=int) # initialize a counting variable\n",
    "for i in range(0,n_tot,1):   # step through EQ catalog\n",
    "    # logical if statements to incorporate definitions of Dtest and Ttest aftershock window bounds\n",
    "    Dtest=np.power(10,0.1238*AE_mag[i]+0.983)   # distance bounds\n",
    "    if AE_mag[i] >= 6.5:\n",
    "        Ttest=np.power(10,0.032*AE_mag[i]+2.7389)  # aftershock time bounds for M >= 6.5\n",
    "    else:\n",
    "        Ttest=np.power(10,0.5409*AE_mag[i]-0.547)  # aftershock time bounds for M < 6.5\n",
    "    \n",
    "    a=AE_days[i+1:n_tot]-AE_days[i]    # time interval in days to subsequent earthquakes in catalog\n",
    "    m=AE_mag[i+1:n_tot]   # magnitudes of subsequent earthquakes in catalog\n",
    "    # distance in km to subsequent EQs in catalog\n",
    "    b=haversine_np(AE_lon[i],AE_lat[i],AE_lon[i+1:n_tot],AE_lat[i+1:n_tot]) \n",
    "    \n",
    "    icnt=np.count_nonzero(a <= Ttest)   # counts the number of potential aftershocks, \n",
    "                                        # the number of intervals <= Ttest bound\n",
    "    if icnt > 0:  # if there are potential aftershocks\n",
    "        itime=np.array(np.nonzero(a <= Ttest)) + (i+1) # indices of potential aftershocks <= Ttest bound\n",
    "        for j in range(0,icnt,1):   # loops over the aftershocks         \n",
    "            if b[j] <= Dtest and m[j] < AE_mag[i]: # test if the event is inside the distance window \n",
    "                                                # and that the event is smaller than the current main EQ\n",
    "                save[0][cnt]=itime[0][j]  # index value of the aftershock\n",
    "                cnt += 1 # increment the counting variable\n",
    "\n",
    "                \n",
    "AF_ind=np.delete(np.unique(save),0)   # This is an array of indexes that will be used to delete events flagged \n",
    "                                      # as aftershocks    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the aftershock events\n",
    "declustered_days=np.delete(AE_days,AF_ind)  #The aftershocks are deleted from the days array \n",
    "declustered_mag=np.delete(AE_mag,AF_ind)    #The aftershocks are deleted from the mag array \n",
    "n_main=len(declustered_days)\n",
    "\n",
    "# select the aftershock events\n",
    "aftershock_days=AE_days[AF_ind]  #The aftershocks are selected from the days array \n",
    "aftershock_mag=AE_mag[AF_ind]    #The aftershocks are selected from the mag array \n",
    "n_after=len(aftershock_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have three earthquake catalogs (raw, declustered, and aftershocks) we will set up the magnitude and $log_{10}$(Number of events per year) arrays which will be fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the observed log10 number of events per year as function of magnitude (data)\n",
    "min_mag=np.min(AE_mag)\n",
    "max_mag=np.max(AE_mag)\n",
    "m_all_events=np.arange(...,...,0.1)\n",
    "N_all_events=np.zeros(len(m_all_events))\n",
    "numyr=(max(AE_days)-min(AE_days))/365\n",
    "for i in range(0,len(m_all_events),1):\n",
    "    N_all_events[i]=np.log10(np.count_nonzero(...)/numyr)\n",
    "    \n",
    "\n",
    "min_mag=np.min(declustered_mag)\n",
    "max_mag=np.max(declustered_mag)\n",
    "m_declustered=...\n",
    "N_declustered=np.zeros(len(m_declustered))\n",
    "numyr=(max(declustered_days)-min(declustered_days))/365\n",
    "for i in range(0,len(m_declustered),1):\n",
    "    N_declustered[i]=...    \n",
    "\n",
    "min_mag=np.min(aftershock_mag)\n",
    "max_mag=np.max(aftershock_mag)  \n",
    "m_aftershock=n...\n",
    "N_aftershock=np.zeros(len(m_aftershock))\n",
    "numyr=(max(aftershock_days)-min(aftershock_days))/365\n",
    "for i in range(0,len(m_aftershock),1):\n",
    "    N_aftershock[i]=..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the observed relationship between M and log10N\n",
    "plt.figure(1,(10,10))\n",
    "plt.plot(m_all_events,N_all_events,'o',color='red',label='Catalog of All Events');\n",
    "plt.plot(m_declustered,N_declustered,'o',color='green',label='Declustered Catalog');\n",
    "plt.plot(m_aftershock,N_aftershock,'o',color='mediumblue',label='Aftershock Catalog');\n",
    "plt.xlim(0, 7);\n",
    "plt.ylim(-2.1, 3);\n",
    "plt.xlabel('Magnitude', fontsize=16);\n",
    "plt.ylabel('Number of earthquakes, $log_{10}$ N', fontsize=16);\n",
    "plt.legend(fontsize=16)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve the least squares problem for the a-value and b-value of the Gutenberg Richter law: $log(N)=a+bm$. \n",
    "\n",
    "$\\begin{bmatrix}\n",
    "1 & m_{1} \\\\ \n",
    "1 & m_{2} \\\\ \n",
    ". & . \\\\\n",
    ". & . \\\\\n",
    ". & . \\\\\n",
    "1 & m_{n}\n",
    "\\end{bmatrix} \\begin{bmatrix}\n",
    "a \\\\\n",
    "b\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "log(y_{1}) \\\\ log(y_{2}) \\\\ . \\\\ . \\\\ . \\\\ log(y_{n}) \\\\\n",
    "\\end{bmatrix} = A M= log(N)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least squares solution for the model parameters is $M = (A{^T}A)^{-1}A{^T}log(N)$. We'll also keep track of how long it takes the computer to solve for the model parameters with `time.time()` which returns the current time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for Model Parameters\n",
    "# Catalog of all events\n",
    "A_all_events = np.column_stack((np.ones(len(m_all_events)), m_all_events))\n",
    "trans_A_all_events = matrix_transpose(A_all_events)\n",
    "ATA_all_events = matrix_mult(trans_A_all_events,A_all_events)\n",
    "ATN_all_events = matrix_mult(trans_A_all_events,matrix_transpose([N_all_events]))\n",
    "inv_all_events = matrix_inv(ATA_all_events)\n",
    "soln_all_events = matrix_mult(inv_all_events,ATN_all_events)\n",
    "x_all_events = m_all_events\n",
    "y_all_events = matrix_mult(A_all_events,soln_all_events)\n",
    "\n",
    "\n",
    "print(A_all_events)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declustered events\n",
    "A_declustered = np.column_stack(..., ...)\n",
    "trans_A_declustered = matrix_transpose(...)\n",
    "ATA_declustered = matrix_mult(...,...)\n",
    "ATN_declustered = matrix_mult(...,matrix_transpose([...]))\n",
    "inv_declustered = matrix_inv(...)\n",
    "soln_declustered = matrix_mult(...)\n",
    "x_declustered = m_declustered\n",
    "y_declustered = matrix_mult(...)\n",
    "\n",
    "\n",
    "# Aftershock events\n",
    "A_aftershock = ...\n",
    "trans_A_aftershock = ...\n",
    "ATA_aftershock = ...\n",
    "ATN_aftershock = ...\n",
    "inv_aftershock = ...\n",
    "soln_aftershock = ...\n",
    "x_aftershock = ...\n",
    "y_aftershock = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig = plt.figure(1,(20,5))\n",
    "grid = plt.GridSpec(1, 3, wspace=0.4, hspace=0.3)\n",
    "\n",
    "ax0=fig.add_subplot(grid[0,0])\n",
    "ax1=fig.add_subplot(grid[0,1])\n",
    "ax2=fig.add_subplot(grid[0,2])\n",
    "\n",
    "ax0.plot(m_all_events,N_all_events,'o',color='red');\n",
    "ax0.plot(x_all_events,y_all_events,'k-');\n",
    "ax0.set_xlim(0, 7);\n",
    "ax0.set_ylim(-2.1, 3);\n",
    "ax0.text(4,2.5,'A value: %7.3f'%(soln_all_events[0]), fontsize=16)\n",
    "ax0.text(4,2.2,'B value: %7.3f'%(soln_all_events[1]), fontsize=16)\n",
    "ax0.set_xlabel('Magnitude', fontsize=16);\n",
    "ax0.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax0.set_title('Catalog of All Events', fontsize=16);\n",
    "ax0.grid()\n",
    "\n",
    "ax1.plot(m_declustered,N_declustered,'o',color='green');\n",
    "ax1.plot(x_declustered,y_declustered,'k-');\n",
    "ax1.set_xlim(0, 7);\n",
    "ax1.set_ylim(-2.1, 3);\n",
    "ax1.text(4,2.5,'A value: %7.3f'%(soln_declustered[0]), fontsize=16)\n",
    "ax1.text(4,2.2,'B value: %7.3f'%(soln_declustered[1]), fontsize=16)\n",
    "ax1.set_xlabel('Magnitude', fontsize=16);\n",
    "ax1.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax1.set_title('Declustered Catalog', fontsize=16);\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(m_aftershock,N_aftershock,'o',color='mediumblue');\n",
    "ax2.plot(x_aftershock,y_aftershock,'k-');\n",
    "ax2.set_xlim(0, 7);\n",
    "ax2.set_ylim(-2.1, 3);\n",
    "ax2.text(4,2.5,'A value: %7.3f'%(soln_aftershock[0]), fontsize=16)\n",
    "ax2.text(4,2.2,'B value: %7.3f'%(soln_aftershock[1]), fontsize=16)\n",
    "ax2.set_xlabel('Magnitude', fontsize=16);\n",
    "ax2.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax2.set_title('Aftershock Catalog', fontsize=16);\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numpy Linear Algebra Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many numpy functions that simplify these matrix operations!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic operations: `np.add(A,B)`, `np.subtract(A,B)`, `np.divide(A,B)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrix multiply: ` A@B`, `np.dot(A,B)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose of matrix $A$: `np.transpose(A)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshaping and combining arrays into matrices: `A.flatten`, `np.hstack((a,b))`, `np.vstack((a,b))`,`np.hsplit(a,2)`, and `np.vsplit(a,2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determinate: `np.linalg.det(A)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse: `np.linalg.inv(A)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve inverse problem: `np.linalg.solve(A,b)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the declustered catalog we want to determine the Gutenberg-Richter parameters for the part of the catalog that is considered complete (M>= magnitude of completeness)\n",
    "\n",
    "#### Regenerate the declustered catalog considering only magnitudes greater than the magnitude of completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write code hear to recompute the A_declustered matrix considering only M greater than the magnitude of completeness\n",
    "min_mag=...\n",
    "max_mag=np.max(declustered_mag)\n",
    "m_declustered=np.arange(min_mag,max_mag,0.1)\n",
    "N_declustered=np.zeros(len(m_declustered))\n",
    "numyr=(max(declustered_days)-min(declustered_days))/365\n",
    "for i in range(0,len(m_declustered),1):\n",
    "    N_declustered[i]=np.log10(np.count_nonzero(declustered_mag >= m_declustered[i])/numyr) \n",
    "\n",
    "A_declustered = np.column_stack((np.ones(len(m_declustered)), m_declustered))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for Model Parameters\n",
    "# Catalog of all events\n",
    "trans_A_all_events = np.transpose(A_all_events)\n",
    "ATA_all_events = trans_A_all_events@A_all_events\n",
    "ATN_all_events = trans_A_all_events@np.transpose([N_all_events])\n",
    "soln_all_events =np.linalg.solve(ATA_all_events,ATN_all_events)\n",
    "x_all_events = m_all_events\n",
    "y_all_events = A_all_events@soln_all_events\n",
    "\n",
    "\n",
    "# Declustered events\n",
    "trans_A_declustered = ...\n",
    "ATA_declustered = ...\n",
    "ATN_declustered = ...\n",
    "soln_declustered = ...\n",
    "x_declustered = ...\n",
    "y_declustered = ...\n",
    "\n",
    "\n",
    "# Aftershock events\n",
    "trans_A_aftershock = ...\n",
    "ATA_aftershock = ...\n",
    "ATN_aftershock = ...\n",
    "soln_aftershock = ...\n",
    "x_aftershock = ...\n",
    "y_aftershock = ...\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig = plt.figure(1,(20,5))\n",
    "grid = plt.GridSpec(1, 3, wspace=0.4, hspace=0.3)\n",
    "\n",
    "ax0=fig.add_subplot(grid[0,0])\n",
    "ax1=fig.add_subplot(grid[0,1])\n",
    "ax2=fig.add_subplot(grid[0,2])\n",
    "\n",
    "ax0.plot(m_all_events,N_all_events,'o',color='red');\n",
    "ax0.plot(x_all_events,y_all_events,'k-');\n",
    "ax0.set_xlim(0, 7);\n",
    "ax0.set_ylim(-2.1, 3);\n",
    "ax0.text(4,2.5,'A value: %7.3f'%(soln_all_events[0]), fontsize=16)\n",
    "ax0.text(4,2.2,'B value: %7.3f'%(soln_all_events[1]), fontsize=16)\n",
    "ax0.set_xlabel('Magnitude', fontsize=16);\n",
    "ax0.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax0.set_title('Catalog of All Events', fontsize=16);\n",
    "ax0.grid()\n",
    "\n",
    "ax1.plot(m_declustered,N_declustered,'o',color='green');\n",
    "ax1.plot(x_declustered,y_declustered,'k-');\n",
    "ax1.set_xlim(0, 7);\n",
    "ax1.set_ylim(-2.1, 3);\n",
    "ax1.text(4,2.5,'A value: %7.3f'%(soln_declustered[0]), fontsize=16)\n",
    "ax1.text(4,2.2,'B value: %7.3f'%(soln_declustered[1]), fontsize=16)\n",
    "ax1.set_xlabel('Magnitude', fontsize=16);\n",
    "ax1.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax1.set_title('Declustered Catalog', fontsize=16);\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(m_aftershock,N_aftershock,'o',color='mediumblue');\n",
    "ax2.plot(x_aftershock,y_aftershock,'k-');\n",
    "ax2.set_xlim(0, 7);\n",
    "ax2.set_ylim(-2.1, 3);\n",
    "ax2.text(4,2.5,'A value: %7.3f'%(soln_aftershock[0]), fontsize=16)\n",
    "ax2.text(4,2.2,'B value: %7.3f'%(soln_aftershock[1]), fontsize=16)\n",
    "ax2.set_xlabel('Magnitude', fontsize=16);\n",
    "ax2.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax2.set_title('Aftershock Catalog', fontsize=16);\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built in Least-squares solvers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we learned last week there are also built in least-squares solvers: `np.linalg.lstsq(A,B)`, `np.polyfit()`, `np.polyval()`, `stats.linregress`, and `statsmodels.OLS()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve for Model Parameters\n",
    "# Catalog of all events\n",
    "soln_all_events =np.polyfit(...,...,1) # np.polyfit(x,y,order)\n",
    "x_all_events = m_all_events\n",
    "y_all_events = np.polyval(...,...) # np.polyval(model_params,x)\n",
    "\n",
    "\n",
    "# Declustered events\n",
    "soln_declustered = ...\n",
    "x_declustered = ...\n",
    "y_declustered = ...\n",
    "\n",
    "\n",
    "# Aftershock events\n",
    "soln_aftershock = ...\n",
    "x_aftershock = ...\n",
    "y_aftershock = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "fig = plt.figure(1,(20,5))\n",
    "grid = plt.GridSpec(1, 3, wspace=0.4, hspace=0.3)\n",
    "\n",
    "ax0=fig.add_subplot(grid[0,0])\n",
    "ax1=fig.add_subplot(grid[0,1])\n",
    "ax2=fig.add_subplot(grid[0,2])\n",
    "\n",
    "ax0.plot(m_all_events,N_all_events,'o',color='red');\n",
    "ax0.plot(x_all_events,y_all_events,'k-');\n",
    "ax0.set_xlim(0, 7);\n",
    "ax0.set_ylim(-2.1, 3);\n",
    "ax0.text(4,2.5,'A value: %7.3f'%(soln_all_events[1]), fontsize=16)\n",
    "ax0.text(4,2.2,'B value: %7.3f'%(soln_all_events[0]), fontsize=16)\n",
    "ax0.set_xlabel('Magnitude', fontsize=16);\n",
    "ax0.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax0.set_title('Catalog of All Events', fontsize=16);\n",
    "ax0.grid()\n",
    "\n",
    "ax1.plot(m_declustered,N_declustered,'o',color='green');\n",
    "ax1.plot(x_declustered,y_declustered,'k-');\n",
    "ax1.set_xlim(0, 7);\n",
    "ax1.set_ylim(-2.1, 3);\n",
    "ax1.text(4,2.5,'A value: %7.3f'%(soln_declustered[1]), fontsize=16)\n",
    "ax1.text(4,2.2,'B value: %7.3f'%(soln_declustered[0]), fontsize=16)\n",
    "ax1.set_xlabel('Magnitude', fontsize=16);\n",
    "ax1.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax1.set_title('Declustered Catalog', fontsize=16);\n",
    "ax1.grid()\n",
    "\n",
    "ax2.plot(m_aftershock,N_aftershock,'o',color='mediumblue');\n",
    "ax2.plot(x_aftershock,y_aftershock,'k-');\n",
    "ax2.set_xlim(0, 7);\n",
    "ax2.set_ylim(-2.1, 3);\n",
    "ax2.text(4,2.5,'A value: %7.3f'%(soln_aftershock[1]), fontsize=16)\n",
    "ax2.text(4,2.2,'B value: %7.3f'%(soln_aftershock[0]), fontsize=16)\n",
    "ax2.set_xlabel('Magnitude', fontsize=16);\n",
    "ax2.set_ylabel('Number of eathquakes, $log_{10}$ N', fontsize=16);\n",
    "ax2.set_title('Aftershock Catalog', fontsize=16);\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did the B-value for the Bay Area change between the raw and declustered catalogs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is the slope (B-value) of the model line for aftershocks steeper or shallower than that for the declustered catalog? Does this indicate there are more or fewer small aftershock events relative to larger events? Is this intuitive? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write your answer here._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the declustered catalog what is the predicted occurance rate of M6+ earthquakes for the Bay Area? What is the log(N) value i.e. `y_declustered` for M6? Raise 10 to the power of `y_declustered` at M6 to find the number of M6+ earthquakes per year. Divide 1 by this power of 10 to find the number of years per earthquake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
